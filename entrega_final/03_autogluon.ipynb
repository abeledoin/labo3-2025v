{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae3d4bc",
   "metadata": {},
   "source": [
    "# AutoGluon - Predicción de ventas (tn) por producto para febrero 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f52d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6eb045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing as mp\n",
    "\n",
    "# # fuerza fork como método de arranque de procesos\n",
    "# try:\n",
    "#     mp.set_start_method(\"fork\", force=True)\n",
    "# except RuntimeError:\n",
    "#     # si ya se había establecido otro método, lo ignoramos\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e8c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATOS     = '/Users/indianaabeledo/Documents/Maestria/laboratorio_III/datasets/'\n",
    "INTERMEDIOS   = '/Users/indianaabeledo/Documents/Maestria/laboratorio_III/entrega_final/intermedios/'\n",
    "BASE_OUTPUTS   = '/Users/indianaabeledo/Documents/Maestria/laboratorio_III/entrega_final/output/'\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "os.makedirs(INTERMEDIOS, exist_ok=True)\n",
    "os.makedirs(BASE_OUTPUTS, exist_ok=True)\n",
    "\n",
    "PRED_PATH = os.path.join(BASE_OUTPUTS,'pred_modelo_autogluon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f6e8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Cargando archivos...\n"
     ]
    }
   ],
   "source": [
    "# Carga de archivos desde Drive\n",
    "print(\"🔄 Cargando archivos...\")\n",
    "productos_pred = pd.read_csv(os.path.join(BASE_DATOS, \"productos_pred.txt\"), sep=\"\\t\")\n",
    "df_sellin      = pd.read_csv(os.path.join(BASE_DATOS, \"sell-in.txt\"),        sep=\"\\t\")\n",
    "df_productos   = pd.read_csv(os.path.join(BASE_DATOS, \"tb_productos.txt\"),   sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374b186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📄 Leer lista de productos a predecir\n",
    "# 1. Asegurar de que sean enteros\n",
    "productos_pred['product_id'] = productos_pred['product_id'].astype(int)\n",
    "\n",
    "# 2. Extrae la lista\n",
    "product_ids = productos_pred['product_id'].tolist()\n",
    "\n",
    "# 🧹 3. Preprocesamiento\n",
    "# Convertir periodo a datetime\n",
    "df_sellin['timestamp'] = pd.to_datetime(df_sellin['periodo'], format='%Y%m')\n",
    "\n",
    "# Filtrar hasta dic 2019 y productos requeridos\n",
    "df_filtered = df_sellin[\n",
    "    (df_sellin['timestamp'] <= '2019-12-01') &\n",
    "    (df_sellin['product_id'].isin(product_ids))\n",
    "]\n",
    "\n",
    "# Agregar tn por periodo, cliente y producto\n",
    "df_grouped = df_filtered.groupby(['timestamp', 'customer_id', 'product_id'], as_index=False)['tn'].sum()\n",
    "\n",
    "# Agregar tn total por periodo y producto\n",
    "df_monthly_product = df_grouped.groupby(['timestamp', 'product_id'], as_index=False)['tn'].sum()\n",
    "\n",
    "# Agregar columna 'item_id' para AutoGluon\n",
    "df_monthly_product['item_id'] = df_monthly_product['product_id']\n",
    "\n",
    "# ⏰ 4. Crear TimeSeriesDataFrame\n",
    "ts_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_monthly_product,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")\n",
    "\n",
    "# Completar valores faltantes\n",
    "ts_data = ts_data.fill_missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a24c835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to '/Users/indianaabeledo/Documents/Maestria/laboratorio_III/entrega_final/AutogluonModels/ag-20250715_231710'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.5.0: Tue Apr 22 19:54:29 PDT 2025; root:xnu-11417.121.6~2/RELEASE_ARM64_T6030\n",
      "CPU Count:          11\n",
      "GPU Count:          0\n",
      "Memory Avail:       2.87 GB / 18.00 GB (15.9%)\n",
      "Disk Space Avail:   322.18 GB / 460.43 GB (70.0%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'IRREG' has been resampled to frequency 'MS'.\n",
      "Provided train_data has 22375 rows (NaN fraction=0.1%), 780 time series. Median time series length is 36 (min=4, max=36). \n",
      "\tRemoving 75 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 21916 rows (NaN fraction=0.1%), 705 time series. Median time series length is 36 (min=9, max=36). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['product_id']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-15 20:17:21\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 275.8s of the 3585.6s of remaining time.\n",
      "\t-0.2298       = Validation score (-WQL)\n",
      "\t4.95    s     = Training runtime\n",
      "\t0.21    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 298.4s of the 3580.4s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2285       = Validation score (-WQL)\n",
      "\t1.32    s     = Training runtime\n",
      "\t0.02    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 325.4s of the 3579.1s of remaining time.\n",
      "\t-0.2436       = Validation score (-WQL)\n",
      "\t12.98   s     = Training runtime\n",
      "\t0.04    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 356.6s of the 3566.1s of remaining time.\n",
      "\t-0.2788       = Validation score (-WQL)\n",
      "\t0.25    s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 396.2s of the 3565.6s of remaining time.\n",
      "\t-0.2039       = Validation score (-WQL)\n",
      "\t1.76    s     = Training runtime\n",
      "\t0.30    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 445.4s of the 3563.5s of remaining time.\n",
      "\tWarning: AutoETS/W0 failed for 45 time series (6.4%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2010       = Validation score (-WQL)\n",
      "\t1.50    s     = Training runtime\n",
      "\t1.64    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 508.6s of the 3560.4s of remaining time.\n",
      "\tWarning: Exception caused ChronosZeroShot[bolt_base] to fail during training... Skipping this model.\n",
      "\tFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 591.3s of the 3547.9s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tWarning: Exception caused ChronosFineTuned[bolt_small] to fail during training... Skipping this model.\n",
      "\tFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 736.9s of the 3547.8s of remaining time.\n",
      "\t-0.1796       = Validation score (-WQL)\n",
      "\t236.65  s     = Training runtime\n",
      "\t0.24    s     = Validation (prediction) runtime\n",
      "Training timeseries model DeepAR. Training for up to 903.6s of the 3310.9s of remaining time.\n",
      "\t-0.1969       = Validation score (-WQL)\n",
      "\t71.39   s     = Training runtime\n",
      "\t0.31    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1319.6s of the 3239.2s of remaining time.\n",
      "\t-0.1860       = Validation score (-WQL)\n",
      "\t39.01   s     = Training runtime\n",
      "\t0.10    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2600.1s of the 3200.1s of remaining time.\n",
      "\t-0.2304       = Validation score (-WQL)\n",
      "\t110.99  s     = Training runtime\n",
      "\t0.24    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.19, 'NPTS': 0.08, 'PatchTST': 0.28, 'SeasonalNaive': 0.04, 'TemporalFusionTransformer': 0.4}\n",
      "\t-0.1711       = Validation score (-WQL)\n",
      "\t0.94    s     = Training runtime\n",
      "\t2.39    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 500.67 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1711\n",
      "data with frequency 'IRREG' has been resampled to frequency 'MS'.\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "\tWarning: AutoETS/W1 failed for 46 time series (5.9%). Fallback model SeasonalNaive was used for these time series.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_id', 'timestamp', 'mean'], dtype='object')\n",
      "✅ Guardado en: /Users/indianaabeledo/Documents/Maestria/laboratorio_III/entrega_final/output/predicciones_modelo_Autogluonv2.csv\n"
     ]
    }
   ],
   "source": [
    "# ⚙️ 5. Definir y entrenar predictor\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=2,\n",
    "    target='tn',\n",
    "    freq='MS'  # Frecuencia mensual (Month Start),\n",
    ")\n",
    "\n",
    "predictor.fit(ts_data, num_val_windows=2, time_limit=60*60)\n",
    "\n",
    "# 🔮 6. Generar predicción\n",
    "forecast = predictor.predict(ts_data)\n",
    "\n",
    "# Extraer predicción media y filtrar febrero 2020\n",
    "forecast_mean = forecast['mean'].reset_index()\n",
    "print(forecast_mean.columns)\n",
    "\n",
    "# Tomar solo item_id y la predicción 'mean'\n",
    "resultado = forecast['mean'].reset_index()[['item_id', 'mean']]\n",
    "resultado.columns = ['product_id', 'tn']\n",
    "\n",
    "# Filtrar solo febrero 2020\n",
    "resultado = forecast['mean'].reset_index()\n",
    "resultado = resultado[resultado['timestamp'] == '2020-02-01'] # Colocar mes a predecir '2020-02-01'\n",
    "\n",
    "# Renombrar columnas\n",
    "resultado = resultado[['item_id', 'mean']]\n",
    "resultado.columns = ['product_id', 'tn']\n",
    "\n",
    "# === 8. Guardar en CSV usando PRED_PATH ===\n",
    "resultado.to_csv(PRED_PATH, index=False)\n",
    "print(f\"✅ Guardado en: {PRED_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e02b94",
   "metadata": {},
   "source": [
    "# Errores 201912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8487259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_monthly tiene [timestamp, item_id, tn, …]\n",
    "df_cut = df_monthly_product.loc[\n",
    "    df_monthly_product['timestamp'] <= '2019-10-01'\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a69d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: autogluon.timeseries\n",
      "Version: 1.3.1\n",
      "Summary: Fast and Accurate ML in 3 Lines of Code\n",
      "Home-page: https://github.com/autogluon/autogluon\n",
      "Author: AutoGluon Community\n",
      "Author-email: \n",
      "License: Apache-2.0\n",
      "Location: /Users/indianaabeledo/Library/Python/3.9/lib/python/site-packages\n",
      "Requires: scipy, mlforecast, pytorch-lightning, orjson, tensorboard, fugue, networkx, autogluon.features, torch, coreforecast, accelerate, joblib, transformers, lightning, autogluon.tabular, gluonts, tqdm, pandas, utilsforecast, autogluon.core, statsforecast, autogluon.common, numpy\n",
      "Required-by: autogluon\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ⏰ 4. Crear TimeSeriesDataFrame\n",
    "ts_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_cut,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")\n",
    "\n",
    "# Completar valores faltantes\n",
    "ts_data = ts_data.fill_missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fef411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ 5. Definir y entrenar predictor\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=2,\n",
    "    target='tn',\n",
    "    freq='MS'  # Frecuencia mensual (Month Start),\n",
    ")\n",
    "\n",
    "predictor.fit(ts_data, num_val_windows=2, time_limit=60*60)\n",
    "\n",
    "# 🔮 6. Generar predicción\n",
    "forecast = predictor.predict(ts_data)\n",
    "\n",
    "# Extraer predicción media y filtrar febrero 2020\n",
    "forecast_mean = forecast['mean'].reset_index()\n",
    "print(forecast_mean.columns)\n",
    "\n",
    "\n",
    "# Tomar solo item_id y la predicción 'mean'\n",
    "resultado = forecast['mean'].reset_index()[['item_id', 'mean']]\n",
    "resultado.columns = ['product_id', 'tn']\n",
    "\n",
    "# Filtrar solo febrero 2020\n",
    "resultado = forecast['mean'].reset_index()\n",
    "resultado = resultado[resultado['timestamp'] == '2019-12-01']#Colocar mes a predecir '2020-02-01'\n",
    "\n",
    "# Renombrar columnas\n",
    "resultado = resultado[['item_id', 'mean']]\n",
    "resultado.columns = ['product_id', 'tn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Filtrar valores reales de diciembre-2019\n",
    "actual = (\n",
    "    df_monthly_product\n",
    "      .query(\"timestamp == '2019-12-01'\")\n",
    "      .loc[:, ['product_id', 'tn']]\n",
    "      .rename(columns={'tn': 'tn_real'})\n",
    ")\n",
    "\n",
    "# 2) Unir predicción y real\n",
    "#    'resultado' debe tener columnas ['product_id','tn'] donde 'tn' es la predicha.\n",
    "df_comp = actual.merge(resultado, on='product_id', how='left')\n",
    "\n",
    "# 3) (Opcional) Agregar / sumar por product_id si hubiera varias filas\n",
    "df_agg = (\n",
    "    df_comp\n",
    "      .groupby('product_id')[['tn_real', 'tn']]\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# 4) Calcular errores\n",
    "df_agg['abs_error'] = (df_agg['tn_real'] - df_agg['tn']).abs()\n",
    "df_agg['pct_error'] = df_agg['abs_error'] / df_agg['tn_real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63802e73",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Definir ruta de salida (reusa BASE_OUTPUTS si ya la tienes)\n",
    "ERROR_CSV_PATH = os.path.join(BASE_OUTPUTS, 'error_201912_autogluon.csv')\n",
    "\n",
    "# Exportar a CSV\n",
    "df_agg.to_csv(ERROR_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"✅ Resultados exportados a: {ERROR_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9062f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>1318.842610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>1088.935465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>718.753417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>546.314163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>529.565386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id           tn\n",
       "0       20001  1318.842610\n",
       "1       20002  1088.935465\n",
       "2       20003   718.753417\n",
       "3       20004   546.314163\n",
       "4       20005   529.565386"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agluon39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
