{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae3d4bc",
   "metadata": {},
   "source": [
    "# AutoGluon - Predicci√≥n de ventas (tn) por producto para febrero 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f52d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6eb045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing as mp\n",
    "\n",
    "# # fuerza fork como m√©todo de arranque de procesos\n",
    "# try:\n",
    "#     mp.set_start_method(\"fork\", force=True)\n",
    "# except RuntimeError:\n",
    "#     # si ya se hab√≠a establecido otro m√©todo, lo ignoramos\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97e8c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATOS     = '/Users/indianaabeledo/Documents/Maestria/laboratorio_III/labo3-2025v/datasets/'\n",
    "INTERMEDIOS   = '/Users/indianaabeledo/Documents/Maestria/laboratorio_III/labo3-2025v/entrega_final/intermedios/'\n",
    "BASE_OUTPUTS   = '/Users/indianaabeledo/Documents/Maestria/laboratorio_III/labo3-2025v/entrega_final/output/'\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "os.makedirs(INTERMEDIOS, exist_ok=True)\n",
    "os.makedirs(BASE_OUTPUTS, exist_ok=True)\n",
    "\n",
    "PRED_PATH = os.path.join(BASE_OUTPUTS,'pred_modelo_autogluon_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65f6e8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Cargando archivos...\n"
     ]
    }
   ],
   "source": [
    "# Carga de archivos desde Drive\n",
    "print(\"üîÑ Cargando archivos...\")\n",
    "productos_pred = pd.read_csv('/Users/indianaabeledo/Documents/Maestria/laboratorio_III/labo3-2025v/entrega_final/datasets/productos_pred.txt')\n",
    "df_sellin      = pd.read_csv('/Users/indianaabeledo/Documents/Maestria/laboratorio_III/labo3-2025v/entrega_final/datasets/sell-in.txt', sep=\"\\t\")\n",
    "df_productos   = pd.read_csv('/Users/indianaabeledo/Documents/Maestria/laboratorio_III/labo3-2025v/entrega_final/datasets/tb_productos.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "374b186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÑ Leer lista de productos a predecir\n",
    "# 1. Asegurar de que sean enteros\n",
    "productos_pred['product_id'] = productos_pred['product_id'].astype(int)\n",
    "\n",
    "# 2. Extrae la lista\n",
    "product_ids = productos_pred['product_id'].tolist()\n",
    "\n",
    "# üßπ 3. Preprocesamiento\n",
    "# Convertir periodo a datetime\n",
    "df_sellin['timestamp'] = pd.to_datetime(df_sellin['periodo'], format='%Y%m')\n",
    "\n",
    "# Filtrar hasta dic 2019 y productos requeridos\n",
    "df_filtered = df_sellin[\n",
    "    (df_sellin['timestamp'] <= '2019-12-01') &\n",
    "    (df_sellin['product_id'].isin(product_ids))\n",
    "]\n",
    "\n",
    "# Agregar tn por periodo, cliente y producto\n",
    "df_grouped = df_filtered.groupby(['timestamp', 'customer_id', 'product_id'], as_index=False)['tn'].sum()\n",
    "\n",
    "# Agregar tn total por periodo y producto\n",
    "df_monthly_product = df_grouped.groupby(['timestamp', 'product_id'], as_index=False)['tn'].sum()\n",
    "\n",
    "# Agregar columna 'item_id' para AutoGluon\n",
    "df_monthly_product['item_id'] = df_monthly_product['product_id']\n",
    "\n",
    "# ‚è∞ 4. Crear TimeSeriesDataFrame\n",
    "ts_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_monthly_product,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")\n",
    "\n",
    "# Completar valores faltantes\n",
    "ts_data = ts_data.fill_missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a24c835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to '/Users/indianaabeledo/Documents/Maestria/laboratorio_III/labo3-2025v/entrega_final/AutogluonModels/ag-20250719_211526'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.5.0: Tue Apr 22 19:54:29 PDT 2025; root:xnu-11417.121.6~2/RELEASE_ARM64_T6030\n",
      "CPU Count:          11\n",
      "GPU Count:          0\n",
      "Memory Avail:       2.88 GB / 18.00 GB (16.0%)\n",
      "Disk Space Avail:   314.57 GB / 460.43 GB (68.3%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'IRREG' has been resampled to frequency 'MS'.\n",
      "Provided train_data has 22375 rows (NaN fraction=0.1%), 780 time series. Median time series length is 36 (min=4, max=36). \n",
      "\tRemoving 75 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 21916 rows (NaN fraction=0.1%), 705 time series. Median time series length is 36 (min=9, max=36). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['product_id']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-19 18:15:32\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.4s of the 3592.8s of remaining time.\n",
      "\t-0.2298       = Validation score (-WQL)\n",
      "\t3.11    s     = Training runtime\n",
      "\t0.15    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.1s of the 3589.5s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2285       = Validation score (-WQL)\n",
      "\t1.93    s     = Training runtime\n",
      "\t0.03    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.1s of the 3587.6s of remaining time.\n",
      "\t-0.2436       = Validation score (-WQL)\n",
      "\t17.08   s     = Training runtime\n",
      "\t0.05    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 357.0s of the 3570.4s of remaining time.\n",
      "\t-0.2767       = Validation score (-WQL)\n",
      "\t0.34    s     = Training runtime\n",
      "\t0.23    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 396.7s of the 3569.9s of remaining time.\n",
      "\t-0.2039       = Validation score (-WQL)\n",
      "\t1.91    s     = Training runtime\n",
      "\t0.33    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 446.0s of the 3567.6s of remaining time.\n",
      "\tWarning: AutoETS/W0 failed for 45 time series (6.4%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2010       = Validation score (-WQL)\n",
      "\t2.04    s     = Training runtime\n",
      "\t2.09    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 509.1s of the 3563.5s of remaining time.\n",
      "\tWarning: Exception caused ChronosZeroShot[bolt_base] to fail during training... Skipping this model.\n",
      "\tFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 592.9s of the 3557.4s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tWarning: Exception caused ChronosFineTuned[bolt_small] to fail during training... Skipping this model.\n",
      "\tFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 739.3s of the 3557.2s of remaining time.\n",
      "\t-0.1796       = Validation score (-WQL)\n",
      "\t275.14  s     = Training runtime\n",
      "\t0.25    s     = Validation (prediction) runtime\n",
      "Training timeseries model DeepAR. Training for up to 893.9s of the 3281.8s of remaining time.\n",
      "\t-0.1969       = Validation score (-WQL)\n",
      "\t84.10   s     = Training runtime\n",
      "\t0.42    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1298.6s of the 3197.2s of remaining time.\n",
      "\t-0.1860       = Validation score (-WQL)\n",
      "\t48.27   s     = Training runtime\n",
      "\t0.11    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2548.8s of the 3148.8s of remaining time.\n",
      "\t-0.2304       = Validation score (-WQL)\n",
      "\t113.94  s     = Training runtime\n",
      "\t0.25    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.21, 'NPTS': 0.1, 'PatchTST': 0.26, 'SeasonalNaive': 0.03, 'TemporalFusionTransformer': 0.39}\n",
      "\t-0.1708       = Validation score (-WQL)\n",
      "\t0.88    s     = Training runtime\n",
      "\t2.83    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 559.83 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1708\n",
      "data with frequency 'IRREG' has been resampled to frequency 'MS'.\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "\tWarning: AutoETS/W1 failed for 46 time series (5.9%). Fallback model SeasonalNaive was used for these time series.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_id', 'timestamp', 'mean'], dtype='object')\n",
      "‚úÖ Guardado en: /Users/indianaabeledo/Documents/Maestria/laboratorio_III/labo3-2025v/entrega_final/output/pred_modelo_autogluon_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# ‚öôÔ∏è 5. Definir y entrenar predictor\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=2,\n",
    "    target='tn',\n",
    "    freq='MS'  # Frecuencia mensual (Month Start),\n",
    ")\n",
    "\n",
    "predictor.fit(ts_data, num_val_windows=2, time_limit=60*60)\n",
    "\n",
    "# üîÆ 6. Generar predicci√≥n\n",
    "forecast = predictor.predict(ts_data)\n",
    "\n",
    "# Extraer predicci√≥n media y filtrar febrero 2020\n",
    "forecast_mean = forecast['mean'].reset_index()\n",
    "print(forecast_mean.columns)\n",
    "\n",
    "# Tomar solo item_id y la predicci√≥n 'mean'\n",
    "resultado = forecast['mean'].reset_index()[['item_id', 'mean']]\n",
    "resultado.columns = ['product_id', 'tn']\n",
    "\n",
    "# Filtrar solo febrero 2020\n",
    "resultado = forecast['mean'].reset_index()\n",
    "resultado = resultado[resultado['timestamp'] == '2020-02-01'] # Colocar mes a predecir '2020-02-01'\n",
    "\n",
    "# Renombrar columnas\n",
    "resultado = resultado[['item_id', 'mean']]\n",
    "resultado.columns = ['product_id', 'tn']\n",
    "\n",
    "# === 8. Guardar en CSV usando PRED_PATH ===\n",
    "resultado.to_csv(PRED_PATH, index=False)\n",
    "print(f\"‚úÖ Guardado en: {PRED_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e02b94",
   "metadata": {},
   "source": [
    "# Errores 201912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8487259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_monthly tiene [timestamp, item_id, tn, ‚Ä¶]\n",
    "df_cut = df_monthly_product.loc[\n",
    "    df_monthly_product['timestamp'] <= '2019-10-01'\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b8a69d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚è∞ 4. Crear TimeSeriesDataFrame\n",
    "ts_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_cut,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")\n",
    "\n",
    "# Completar valores faltantes\n",
    "ts_data = ts_data.fill_missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15fef411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to '/Users/indianaabeledo/Documents/Maestria/laboratorio_III/labo3-2025v/entrega_final/AutogluonModels/ag-20250719_212725'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.5.0: Tue Apr 22 19:54:29 PDT 2025; root:xnu-11417.121.6~2/RELEASE_ARM64_T6030\n",
      "CPU Count:          11\n",
      "GPU Count:          0\n",
      "Memory Avail:       3.04 GB / 18.00 GB (16.9%)\n",
      "Disk Space Avail:   314.53 GB / 460.43 GB (68.3%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 2,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'IRREG' has been resampled to frequency 'MS'.\n",
      "Provided train_data has 20815 rows (NaN fraction=0.1%), 780 time series. Median time series length is 34 (min=2, max=34). \n",
      "\tRemoving 120 short time series from train_data. Only series with length >= 9 will be used for training.\n",
      "\tAfter filtering, train_data has 20176 rows (NaN fraction=0.1%), 660 time series. Median time series length is 34 (min=9, max=34). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['product_id']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-19 18:27:30\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.5s of the 3595.0s of remaining time.\n",
      "\t-0.2621       = Validation score (-WQL)\n",
      "\t3.26    s     = Training runtime\n",
      "\t0.19    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 299.3s of the 3591.5s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-0.2318       = Validation score (-WQL)\n",
      "\t2.54    s     = Training runtime\n",
      "\t0.03    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 326.3s of the 3588.9s of remaining time.\n",
      "\t-0.2407       = Validation score (-WQL)\n",
      "\t32.70   s     = Training runtime\n",
      "\t0.17    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 355.6s of the 3556.1s of remaining time.\n",
      "\t-0.3171       = Validation score (-WQL)\n",
      "\t0.30    s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 395.1s of the 3555.6s of remaining time.\n",
      "\t-0.2091       = Validation score (-WQL)\n",
      "\t1.34    s     = Training runtime\n",
      "\t0.26    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 444.2s of the 3553.9s of remaining time.\n",
      "\tWarning: AutoETS/W0 failed for 4 time series (0.6%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-0.2143       = Validation score (-WQL)\n",
      "\t1.50    s     = Training runtime\n",
      "\t1.77    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 507.2s of the 3550.7s of remaining time.\n",
      "\tWarning: Exception caused ChronosZeroShot[bolt_base] to fail during training... Skipping this model.\n",
      "\tFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 591.7s of the 3550.4s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tWarning: Exception caused ChronosFineTuned[bolt_small] to fail during training... Skipping this model.\n",
      "\tFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 737.6s of the 3550.3s of remaining time.\n",
      "\t-0.1885       = Validation score (-WQL)\n",
      "\t198.37  s     = Training runtime\n",
      "\t0.21    s     = Validation (prediction) runtime\n",
      "Training timeseries model DeepAR. Training for up to 917.2s of the 3351.7s of remaining time.\n",
      "\t-0.1878       = Validation score (-WQL)\n",
      "\t78.65   s     = Training runtime\n",
      "\t0.37    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 1336.3s of the 3272.7s of remaining time.\n",
      "\t-0.1853       = Validation score (-WQL)\n",
      "\t54.27   s     = Training runtime\n",
      "\t0.10    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 2618.3s of the 3218.3s of remaining time.\n",
      "\t-0.2222       = Validation score (-WQL)\n",
      "\t94.16   s     = Training runtime\n",
      "\t0.23    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoETS': 0.05, 'DeepAR': 0.29, 'NPTS': 0.07, 'PatchTST': 0.32, 'SeasonalNaive': 0.02, 'TemporalFusionTransformer': 0.25}\n",
      "\t-0.1777       = Validation score (-WQL)\n",
      "\t0.99    s     = Training runtime\n",
      "\t2.84    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE', 'WeightedEnsemble']\n",
      "Total runtime: 472.13 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1777\n",
      "data with frequency 'IRREG' has been resampled to frequency 'MS'.\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n",
      "\tWarning: AutoETS/W1 failed for 75 time series (9.6%). Fallback model SeasonalNaive was used for these time series.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_id', 'timestamp', 'mean'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# ‚öôÔ∏è 5. Definir y entrenar predictor\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=2,\n",
    "    target='tn',\n",
    "    freq='MS'  # Frecuencia mensual (Month Start),\n",
    ")\n",
    "\n",
    "predictor.fit(ts_data, num_val_windows=2, time_limit=60*60)\n",
    "\n",
    "# üîÆ 6. Generar predicci√≥n\n",
    "forecast = predictor.predict(ts_data)\n",
    "\n",
    "# Extraer predicci√≥n media y filtrar febrero 2020\n",
    "forecast_mean = forecast['mean'].reset_index()\n",
    "print(forecast_mean.columns)\n",
    "\n",
    "\n",
    "# Tomar solo item_id y la predicci√≥n 'mean'\n",
    "resultado = forecast['mean'].reset_index()[['item_id', 'mean']]\n",
    "resultado.columns = ['product_id', 'tn']\n",
    "\n",
    "# Filtrar solo febrero 2020\n",
    "resultado = forecast['mean'].reset_index()\n",
    "resultado = resultado[resultado['timestamp'] == '2019-12-01']#Colocar mes a predecir '2020-02-01'\n",
    "\n",
    "# Renombrar columnas\n",
    "resultado = resultado[['item_id', 'mean']]\n",
    "resultado.columns = ['product_id', 'tn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27eb3800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c5/g8wp4j8j1nd226rj0lw9_vz40000gn/T/ipykernel_72589/276186870.py:3: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df_monthly_product\n"
     ]
    }
   ],
   "source": [
    "# 1) Filtrar valores reales de diciembre-2019\n",
    "actual = (\n",
    "    df_monthly_product\n",
    "      .query(\"timestamp == '2019-12-01'\")\n",
    "      .loc[:, ['product_id', 'tn']]\n",
    "      .rename(columns={'tn': 'tn_real'})\n",
    ")\n",
    "\n",
    "# 2) Unir predicci√≥n y real\n",
    "#    'resultado' debe tener columnas ['product_id','tn'] donde 'tn' es la predicha.\n",
    "df_comp = actual.merge(resultado, on='product_id', how='left')\n",
    "\n",
    "# 3) (Opcional) Agregar / sumar por product_id si hubiera varias filas\n",
    "df_agg = (\n",
    "    df_comp\n",
    "      .groupby('product_id')[['tn_real', 'tn']]\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# 4) Calcular errores\n",
    "df_agg['abs_error'] = (df_agg['tn_real'] - df_agg['tn']).abs()\n",
    "df_agg['pct_error'] = df_agg['abs_error'] / df_agg['tn_real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63802e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados exportados a: /Users/indianaabeledo/Documents/Maestria/laboratorio_III/labo3-2025v/entrega_final/output/error_201912_autogluon_v2.csv\n"
     ]
    }
   ],
   "source": [
    " #Definir ruta de salida (reusa BASE_OUTPUTS si ya la tienes)\n",
    "ERROR_CSV_PATH = os.path.join(BASE_OUTPUTS, 'error_201912_autogluon_v2.csv')\n",
    "\n",
    "# Exportar a CSV\n",
    "df_agg.to_csv(ERROR_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"‚úÖ Resultados exportados a: {ERROR_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f658f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>1405.702499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20002</td>\n",
       "      <td>1179.900425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20003</td>\n",
       "      <td>811.212572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20004</td>\n",
       "      <td>626.217216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20005</td>\n",
       "      <td>610.200773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id           tn\n",
       "1       20001  1405.702499\n",
       "3       20002  1179.900425\n",
       "5       20003   811.212572\n",
       "7       20004   626.217216\n",
       "9       20005   610.200773"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9062f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>1318.842610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>1088.935465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>718.753417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>546.314163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>529.565386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id           tn\n",
       "0       20001  1318.842610\n",
       "1       20002  1088.935465\n",
       "2       20003   718.753417\n",
       "3       20004   546.314163\n",
       "4       20005   529.565386"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agluon39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
